# RGB_Event_Tracking_Benchmark
The First Benchmark for fusing RGB and Event flow for Reliable Object Tracking


## VisEvent: 
![visevent-example](https://github.com/wangxiao5791509/RGB_Event_Tracking_Benchmark/blob/main/videosamples.png)
The source code of baseline trackers by fusing dual-modalities can be found at: [[DualModality_SOT_Python3](https://github.com/wangxiao5791509/DualModality_SOT_Python3)]. 





















## Synthetic Dataset: 
The synthetic visual tracking dataset [[NfS-V2E](http://ci2cv.net/nfs/index.html)] is provided for Evaluation using toolkit [[V2E](https://github.com/SensorsINI/v2e)]. 







## Citation: 
If you use our dataset or the synthetic RGBE-NfS dataset, please cite the following papers: 

~~~
@article{wang2021rgbeventbenchmark,
  title={Object Tracking using Event and Frame Cameras: Benchmark Dataset and Baseline},
  author={ Xiao Wang, Jianing Li, Lin Zhu, Zhe Chen, Yi Chang, Yaowei Wang, Yonghong Tian, Feng Wu },
  journal={arXiv preprint},
  year={2021}
}

@inproceedings{kiani2017nfs,
  title={Need for speed: A benchmark for higher frame rate object tracking},
  author={Kiani Galoogahi, Hamed and Fagg, Ashton and Huang, Chen and Ramanan, Deva and Lucey, Simon},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1125--1134},
  year={2017}
}

~~~





















